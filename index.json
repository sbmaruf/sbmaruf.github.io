[{"authors":["admin"],"categories":null,"content":"I am M Saiful Bari. You may also call me Maruf. I am a doctoral candidate at NTU, Singapore. My supervisor is Prof. Dr. Shafiq Joty. My research objective is to develop deep models that have the notion of humanity (brain motivated). I spend a huge amount of time and effort exploring unsupervised training and their potential contribution to the generalizability and distributional shift of the language model (LM). In my early work, I investigated adversarial training and semi-supervised learning to transfer knowledge from a high resource to a low resource language. My recent work largely involves efficient transductive few-shot inference and parameter efficient multitask inference via prompt tuning. At the core of my work, I investigate distribution shifts between training vs inference data and how we can solve this distributional shift using various methods (i.e., semi-supervised learning, multitask discrete prompting, data distillation, model distillation etc). I love tooling, debugging and training large language models.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://sbmaruf.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"I am M Saiful Bari. You may also call me Maruf. I am a doctoral candidate at NTU, Singapore. My supervisor is Prof. Dr. Shafiq Joty. My research objective is to develop deep models that have the notion of humanity (brain motivated). I spend a huge amount of time and effort exploring unsupervised training and their potential contribution to the generalizability and distributional shift of the language model (LM). In my early work, I investigated adversarial training and semi-supervised learning to transfer knowledge from a high resource to a low resource language.","tags":null,"title":"M Saiful Bari","type":"author"},{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536422400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536422400,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"https://sbmaruf.github.io/tutorial/","publishdate":"2018-09-09T00:00:00+08:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":["Niklas Muennighoff","Thomas Wang","Lintang Sutawika","Adam Roberts","Stella Biderman","Teven Le Scao","M Saiful Bari","Sheng Shen","Zheng-Xin Yong","Hailey Schoelkopf","Xiangru Tang","Dragomir Radev","Alham Fikri Aji","Khalid Almubarak","Samuel Albanie","Zaid Alyafeai","Albert Webson","Edward Raff","Colin Raffel"],"categories":null,"content":"","date":1667404800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667404800,"objectID":"339a934dcc6d13bae8d5770c459544c8","permalink":"https://sbmaruf.github.io/publication/xmtf/","publishdate":"2022-11-03T00:00:00+08:00","relpermalink":"/publication/xmtf/","section":"publication","summary":"Shows multitask multilingual generalization in language model.","tags":["deep-learning","language-model"],"title":"Multitask Prompted Training Enables Zero-Shot Task Generalization","type":"publication"},{"authors":["Teven Le Scao","Thomas Wang","Daniel Hesslow","Lucile Saulnier","Stas Bekman","M Saiful Bari","Stella Biderman","Hady Elsahar","Jason Phang","Ofir Press","Colin Raffel","Victor Sanh","Sheng Shen","Lintang Sutawika","Jaesung Tae","Zheng Xin Yong","Julien Launay","Iz Beltagy"],"categories":null,"content":"","date":1646064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646064000,"objectID":"f27f88c5b012aabb65eff53d095a7b65","permalink":"https://sbmaruf.github.io/publication/llm/","publishdate":"2022-03-01T00:00:00+08:00","relpermalink":"/publication/llm/","section":"publication","summary":"The crystallization of modeling methods around the Transformer architecture has been a boon for practitioners. Simple, well-motivated architectural variations that transfer across tasks and scale, increasing the impact of modeling research. However, with the emergence of state-of-the-art 100B+ parameters models, large language models are increasingly expensive to accurately design and train. Notably, it can be difficult to evaluate how modeling decisions may impact emergent capabilities, given that these capabilities arise mainly from sheer scale.Targeting a multilingual language model in the 100B+ parameters scale, our goal is to identify an architecture and training setup that makes the best use of our 1,000,000 A100-GPU-hours budget. Specifically, we perform an ablation study comparing different modeling practices and their impact on zero-shot generalization. We perform all our experiments on 1.3B models, providing a compromise between compute costs and the likelihood that our conclusions will hold for the target 100B+ model. In addition, we study the impact of various popular pretraining corpora on zero-shot generalization. We also study the performance of a multilingual model and how it compares to the English-only one. Finally, we consider the scaling behaviour of Transformers to chose the target model size, shape, and training setup.","tags":["deep-learning","multi-lingual","language-model"],"title":"What Language Model to Train if You Have One Million GPU Hours?","type":"publication"},{"authors":["M Saiful Bari"],"categories":null,"content":" Click on the **Slides** button above to view the built-in slides feature.   -- ","date":1644251400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644251400,"objectID":"c8c1ddc0c9553303c8b3824af1632706","permalink":"https://sbmaruf.github.io/talk/t0++/","publishdate":"2022-02-07T00:00:00+08:00","relpermalink":"/talk/t0++/","section":"talk","summary":"A talk on T0++ paper.","tags":["deep-learning","architecture"],"title":"Multitask Prompted Training Enables Zero-Shot Task Generalization","type":"talk"},{"authors":["Stephen H. Bach","Victor Sanh","Zheng-Xin Yong","Albert Webson","Colin Raffel","Nihal V. Nayak","Abheesht Sharma","Taewoon Kim","M Saiful Bari","Thibault Fevry","Zaid Alyafeai","Manan Dey","Andrea Santilli","Zhiqing Sun","Srulik Ben-David","Canwen Xu","Gunjan Chhablani","Han Wang","Jason Alan Fries","Maged S. Al-shaibani","Shanya Sharma","Urmish Thakker","Khalid Almubarak","Xiangru Tang","Xiangru Tang","Mike Tian-Jian Jiang","Alexander M. Rush"],"categories":null,"content":"","date":1643731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643731200,"objectID":"035f81d807b1440f9b479b826b522c85","permalink":"https://sbmaruf.github.io/publication/promptsource/","publishdate":"2022-02-02T00:00:00+08:00","relpermalink":"/publication/promptsource/","section":"publication","summary":"Over 2,000 prompts for roughly 170 datasets are available through PromptSource framework.","tags":["deep-learning","language-model"],"title":"PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts","type":"publication"},{"authors":["Victor Sanh","Albert Webson","Colin Raffel","Stephen H. Bach","Lintang Sutawika","Zaid Alyafeai","Antoine Chaffin","Arnaud Stiegler","Teven Le Scao","Arun Raja","Manan Dey","M Saiful Bari","Canwen Xu","Urmish Thakker","Shanya Sharma Sharma","Eliza Szczechla","Taewoon Kim","Gunjan Chhablani","Nihal Nayak","Debajyoti Datta","Jonathan Chang","Mike Tian-Jian Jiang","Han Wang","Matteo Manica","Sheng Shen","Zheng Xin Yong","Harshit Pandey","Rachel Bawden","Thomas Wang","Trishala Neeraj","Jos Rozen","Abheesht Sharma","Andrea Santilli","Thibault Fevry","Jason Alan Fries","Ryan Teehan","Stella Biderman","Leo Gao","Tali Bers","Thomas Wolf","Alexander M. Rush"],"categories":null,"content":"","date":1634227200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634227200,"objectID":"66c6ebc251826d342cb12beedeca2a38","permalink":"https://sbmaruf.github.io/publication/t0pp/","publishdate":"2021-10-15T00:00:00+08:00","relpermalink":"/publication/t0pp/","section":"publication","summary":"T0 shows zero-shot task generalization on English natural language prompts, outperforming GPT-3 on many tasks, while being 16x smaller!","tags":["deep-learning","language-model"],"title":"Multitask Prompted Training Enables Zero-Shot Task Generalization","type":"publication"},{"authors":["M Saiful Bari","Batool Haider","Saab Mansour"],"categories":null,"content":"","date":1632326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632326400,"objectID":"7312130cf7c958697583d5337e586665","permalink":"https://sbmaruf.github.io/publication/nn/","publishdate":"2021-09-23T00:00:00+08:00","relpermalink":"/publication/nn/","section":"publication","summary":"We propose a trasductive approach for few shot cross-lingual classification.","tags":["deep-learning","cross-lingual","language-model"],"title":"Nearest Neighbour Few-Shot Learning for Cross-lingual Classification","type":"publication"},{"authors":[],"categories":null,"content":" Click on the **Slides** button above to view the built-in slides feature.   -- ","date":1632306600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632306600,"objectID":"c108e162044669c22b0ff7997a53a5b7","permalink":"https://sbmaruf.github.io/talk/flan/","publishdate":"2021-09-22T00:00:00+08:00","relpermalink":"/talk/flan/","section":"talk","summary":"This talk summarizes the paper [`Finetuned Language Models Are Zero-Shot Learners`](https://arxiv.org/abs/2109.01652).","tags":["Deep-Learning"],"title":"Finetuned Language Models Are Zero-Shot Learners","type":"talk"},{"authors":[],"categories":null,"content":"","date":1622376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622376000,"objectID":"3db9138a4303c1dc0dc94edac90b370c","permalink":"https://sbmaruf.github.io/talk/gpt-3/","publishdate":"2021-05-30T00:00:00+08:00","relpermalink":"/talk/gpt-3/","section":"talk","summary":"This talk summarizes the paper [`Language Models are Few-Shot Learners`](https://arxiv.org/abs/2005.14165).","tags":["Deep-Learning"],"title":"GPT-3: Language Models are Few-Shot Learners","type":"talk"},{"authors":["Tasnim Mohiuddin","M Saiful Bari","Shafiq Joty"],"categories":null,"content":"","date":1619798400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619798400,"objectID":"f04a2be6a5e5e85f8095671139c2e453","permalink":"https://sbmaruf.github.io/publication/augvic/","publishdate":"2021-05-01T00:00:00+08:00","relpermalink":"/publication/augvic/","section":"publication","summary":"We propose AugVic, a data augmentation framework for sequence to sequence model (i.e. NMT) using Language Model.","tags":["deep-learning","cross-lingual","language-model"],"title":"AugVic: Exploiting BiText Vicinity for Low-Resource NMT","type":"publication"},{"authors":["M Saiful Bari","Tasnim Mohiuddin","Shafiq Joty"],"categories":null,"content":"","date":1588176000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588176000,"objectID":"bf7ca0648cb00755bd72785c80ee3407","permalink":"https://sbmaruf.github.io/publication/uxla/","publishdate":"2020-04-30T00:00:00+08:00","relpermalink":"/publication/uxla/","section":"publication","summary":"We propose UXLA, a novel data augmentation framework for self-supervised learning in zero-resource transfer learning scenarios.","tags":["deep-learning","cross-lingual","language-model"],"title":"UXLA: A Robust Unsupervised Data Augmentation Framework for Zero-Resouce Cross-Lingual NLP","type":"publication"},{"authors":["Tasnim Mohiuddin","M Saiful Bari","Shafiq Joty"],"categories":null,"content":"","date":1588003200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588003200,"objectID":"c2e197584e836ad959efb3b402fe2a91","permalink":"https://sbmaruf.github.io/publication/lnmap/","publishdate":"2020-04-28T00:00:00+08:00","relpermalink":"/publication/lnmap/","section":"publication","summary":"We propose a novel semi-supervised method to learn cross-lingual word embeddings for BLI.","tags":["deep-learning","cross-lingual","word-embedding"],"title":"LNMAP: Departures from Isomorphic Assumption in Bilingual Lexicon Induction Through Non-Linear Mapping in Latent Space","type":"publication"},{"authors":[],"categories":null,"content":"This talk goes though the pretraining objectives of seq2seq architecture. It also discusses, how mBART is different from pretraining of XLM and it\u0026rsquo;s derivatives?\n Click on the **Slides** button above to view the built-in slides feature.   -- ","date":1587814200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587814200,"objectID":"052b1eef0aaacb5f2287dd25669b7169","permalink":"https://sbmaruf.github.io/talk/mbart/","publishdate":"2018-04-25T00:00:00+08:00","relpermalink":"/talk/mbart/","section":"talk","summary":"This talk summarizes the paper [`mBART`](https://arxiv.org/abs/2001.08210) and some pretraining concepts.","tags":["deep-learning","language-model","machine-translation"],"title":"mBART: pretraining seq2seq architecture","type":"talk"},{"authors":["M Saiful Bari","Shafiq Joty","Prathyusha Jwalapuram"],"categories":null,"content":"","date":1573660800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573660800,"objectID":"0a893120330887630c35b55013714c33","permalink":"https://sbmaruf.github.io/publication/cross-lingual-ner/","publishdate":"2019-11-14T00:00:00+08:00","relpermalink":"/publication/cross-lingual-ner/","section":"publication","summary":"We propose a superior model and training method for zero resource transfer of Cross-lingual Named Entity Recognition.","tags":["deep-learning","cross-lingual","word-embedding"],"title":"Zero-Resource Cross-Lingual Named Entity Recognition","type":"publication"},{"authors":[],"categories":null,"content":" Click on the **Slides** button above to view the built-in slides feature.   -- ","date":1565019000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565019000,"objectID":"4b6a7ae3c6b39ef5119f3fb6243ec96b","permalink":"https://sbmaruf.github.io/talk/semi-sup/","publishdate":"2018-03-21T00:00:00+08:00","relpermalink":"/talk/semi-sup/","section":"talk","summary":"This talk summarizes the paper [`mixup`](https://arxiv.org/abs/1710.09412), [`MixMatch`](https://arxiv.org/abs/1905.02249), [`DivideMix`](https://openreview.net/pdf?id=HJgExaVtwr), [`UDA`](https://arxiv.org/abs/1904.12848).","tags":["deep-learning","semi-sup-learning"],"title":"Semi-Supervised Training","type":"talk"},{"authors":[],"categories":null,"content":" Click on the **Slides** button above to view the built-in slides feature.   -- ","date":1562340600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562340600,"objectID":"9a63bb05156d88080313bde1cc0183af","permalink":"https://sbmaruf.github.io/talk/transformer-xl/","publishdate":"2019-07-05T00:00:00+08:00","relpermalink":"/talk/transformer-xl/","section":"talk","summary":"This talk summarizes the paper [`Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context`](https://arxiv.org/abs/1901.02860). It assumes that audience are already familier with [`Attention Is All You Need`](https://arxiv.org/abs/1706.03762) paper and also discuss some high level concepts of it.","tags":["deep-learning","architecture","language-model"],"title":"Transforme-XL","type":"talk"},{"authors":["Xiang Lin","Shafiq Joty","Prathyusha Jwalapuram","M Saiful Bari"],"categories":null,"content":"","date":1557849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557849600,"objectID":"5d166dc4fed2fd3b8c79b2624add7f23","permalink":"https://sbmaruf.github.io/publication/pointer-net-parser/","publishdate":"2019-05-15T00:00:00+08:00","relpermalink":"/publication/pointer-net-parser/","section":"publication","summary":"We propose an efficient neural framework for sentence-level discourse analysis in accordance with Rhetorical Structure Theory (RST). Our  framework comprises a discourse segmenter to identify the elementary discourse units (EDU) in a text, and a discourse parser that constructs a discourse  tree in a top-down fashion. Both the segmenter and the parser are based on Pointer Networks and operate in linear time. Our segmenter yields an F1 score  of 95.4, and our parser achieves an F1 score of 81.7 on the aggregated labeled (relation) metric, surpassing previous approaches by a good margin and  approaching human agreement on both tasks (98.3 and 83.0 F1).","tags":["discouse-parsing"],"title":"A Unified Linear-Time Framework for Sentence-Level Discourse Parsing","type":"publication"},{"authors":["M Saiful Bari"],"categories":[],"content":" from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and Jupyter Install Anaconda which includes Python 3 and Jupyter notebook.\nOtherwise, for advanced users, install Jupyter notebook with pip3 install jupyter.\nCreate a new blog post as usual Run the following commands in your Terminal, substituting \u0026lt;MY_WEBSITE_FOLDER\u0026gt; and my-post with the file path to your Academic website folder and a name for your blog post (without spaces), respectively:\ncd \u0026lt;MY_WEBSITE_FOLDER\u0026gt; hugo new --kind post post/my-post cd \u0026lt;MY_WEBSITE_FOLDER\u0026gt;/content/post/my-post/  Create or upload a Jupyter notebook Run the following command to start Jupyter within your new blog post folder. Then create a new Jupyter notebook (New \u0026gt; Python Notebook) or upload a notebook.\njupyter notebook  Convert notebook to Markdown jupyter nbconvert Untitled.ipynb --to markdown --NbConvertApp.output_files_dir=. # Copy the contents of Untitled.md and append it to index.md: cat Untitled.md | tee -a index.md # Remove the temporary file: rm Untitled.md  Edit your post metadata Open index.md in your text editor and edit the title etc. in the front matter according to your preference.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://sbmaruf.github.io/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":null,"categories":null,"content":" C++ Implementation of variety of Algorithms and some mush have cheetsheets for CS Students.\nCheet Sheets  Trigonometry Cheat sheet Computer Science Cheat sheet : Mainly series, algorithm discrete math and calculus based cheat sheet. ICPC Cheatsheet : Outdated, may be helpful for beginners.  Data Structure In no particular order,\n- Binary Indexed tree (BIT) - Heavy Light Decomposition (HLD) - Histrogram - LCA - RMQ - trie  Geometry In no particular order,\n- CircleSegmentTetrahedron - Closest Pair - ConvexHull - ConvexHull GrahamScan - ConvexHull MonotoneChain - Parametric Geometry routine - Line segment intersection - Ray casting algorithm (PointInPolygon) - Rotate point - Tangent of line  Graph In no particular order, - Stoer Wagner all pair Min Cut - Articulation Point - Bellman Ford - BiConnected Component - Bridge - Disjoint Set - Eular Circuit - Hungerian Algorithm - Max Weighted Bi-partite Matching - MaxFlow Dinic - Maximum Bipertite Matching - Mincost Max Flow - Minimum Expression - Dinitz - Dinitz With EdgeList - Stable marrige problem - Strongly Connected Component - Tarjans Off line LCA - manacher\nMatrix \u0026amp; Numeric In no particular order,\n- Big float (C++ library) - BigInt - FFT - Faussian Elimination - matrix Exponentiation  Number theory and Math In no particular order,\n- ExtendedEuclidMOdInverse - Hn - LinearDiphontine - Number Theory Part 1.pdf - Good colelction of Number theoric discussion. - NumberTheory Part 2.pdf - Good colelction of Number theoric discussion. - PollardRho - SegmentedSieve - ShankBabyStepGiantStep - Sieve - josepheous - ncr  Searching - Ternary Search  String - Aho Chorasik - KMP - Hashing - suffix-array.pdf - Good discussion of suffix-array - Suffix array code.  IO - Fast read C++  Collected Library  Stanford University ACM Team Notebook : Outdated, maybe helpful for mid-level/above mid-level problem solver.  Combinatorial optimization1.  Sparse max-flow (C++) Min-cost max-flow (C++) Push-relabel max-flow (C++) Min-cost matching (C++) Max bipartite matching (C++) Global min cut (C++) Graph cut inference (C++)  Geometry  Convex hull (C++) Miscellaneous geometry (C++) Java geometry (Java) 3D geometry (Java) Slow Delaunay triangulation (C++)  Numerical algorithms  Number theoretic algorithms (modular, Chinese remainder, linear Diophantine) (C++) Systems of linear equations, matrix inverse, determinant (C++) Reduced row echelon form, matrix rank (C++) Fast Fourier transform (C++) Simplex algorithm (C++)  Graph algorithms  Fast Dijkstra\u0026rsquo;s algorithm (C++) Strongly connected components \u0026copy; Eulerian Path (C++)  Data structures  Suffix arrays (C++) Binary Indexed Tree Union-Find Set (C/C++) KD-tree (C++) Lazy Segment Tree (Java) Lowest Common Ancestor (C++)  Miscellaneous  Longest increasing subsequence (C++) Dates (C++) Regular expressions (Java) Prime numbers (C++) C++ input/output Knuth-Morris-Pratt (C++)  Stavropol SU : Extremely outdated, but worth to look at.  vimrc Java template Combinatorics Number Theory String Algorithms Min-cost max-flow Graph Theory Games Geometry Math Data Structures Miscellanious 13FFT     Special Thanks: My trainer Tarif Ezaz and my friend Mohammad Abdullah Matin Khan Zarzis to whom I learned to think.\nI also want to mention some of the other special names for their tremendous support. Nafis Ahmed, Mohammad Samiul Islam, Zobayer Hasan, Forhad Ahmed and Leonardo Boshell\nNOTE : I don\u0026rsquo;t claim all of the soutions to be mine. While I was solving the problems, I took help from different peoples and see other people\u0026rsquo;s code for many problems. In Fact most of the coder here is collected. But I never submit any code without my complete understanding. I suugest those who will be following the repo to do so. Pasting code to online judges won\u0026rsquo;t take you any further except frustration.\n","date":1548777600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548777600,"objectID":"01c23b42f68c0c2260cf4b7ed5765fe1","permalink":"https://sbmaruf.github.io/project/algorithms-code-library/","publishdate":"2019-01-30T00:00:00+08:00","relpermalink":"/project/algorithms-code-library/","section":"project","summary":"C++ implementation of various algorithms.","tags":["Algorithms"],"title":"Algorithms-Code-Library","type":"project"},{"authors":null,"categories":null,"content":" 2012 OIC Scholarship for undergraduate study, Islamic University of Technology.    2014 Champion, IUT Computer Programming Contest.    2014 Honorable Mention, Human Expedition on Mars Timeline 2018.    2016 2nd/100 in Inter University Programming Contest, Daffodill International University ACM ICPC world finals warmup contest 2016    2016 6th/100+ in Inter University Programming Contest, NSU Cybernauts National Programming Contest    2019 NTU Research Scholarship, Fully funded Ph.D. scholarship for 4 years.    ","date":1548345600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548345600,"objectID":"cf8de4cf088739dbf135a9034ab2931a","permalink":"https://sbmaruf.github.io/post/awards/","publishdate":"2019-01-25T00:00:00+08:00","relpermalink":"/post/awards/","section":"post","summary":"2012 OIC Scholarship for undergraduate study, Islamic University of Technology.    2014 Champion, IUT Computer Programming Contest.    2014 Honorable Mention, Human Expedition on Mars Timeline 2018.    2016 2nd/100 in Inter University Programming Contest, Daffodill International University ACM ICPC world finals warmup contest 2016    2016 6th/100+ in Inter University Programming Contest, NSU Cybernauts National Programming Contest    2019 NTU Research Scholarship, Fully funded Ph.","tags":null,"title":"HONORS \u0026 AWARDS","type":"post"},{"authors":null,"categories":null,"content":"This is a tool to translate an English sentence into Malay and vice versa. Developing a translation tool for low-resource languages like Malay has always been a challenge. The main challenge comes from the fact that machine translation systems typically rely on a huge amount of sentence-parallel data, and creating such datasets is an expensive process. In our work, we collected parallel datasets from various sources including News, OpenSubtitiles (OPUS), Ted talks, and Youtube video. Therefore, our corpus is quite generic and covers both texts and conversations.\nWe used various state of the art deep Neural Machine Translation (NMT) architecture for training our model. More specifically we use both seq2seq and transformer-net architecture for finding our best model. For pre-processing and post-processing datasets we used various tools of moses. To train our model we used OpenNMT-py framework which is very standard in the NMT community for it\u0026rsquo;s robust and modular implementation.\nCurrently the live demo can only be accessed from inside NTU network. \n","date":1548345600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548345600,"objectID":"a0346612fe8c4e999079b44dc91b23c6","permalink":"https://sbmaruf.github.io/project/mt-system/","publishdate":"2019-01-25T00:00:00+08:00","relpermalink":"/project/mt-system/","section":"project","summary":"This is a tool to translate an English sentence into Malay and vice versa.","tags":["Deep Learning"],"title":"Malay-English Neural Machine Translation System.","type":"project"},{"authors":["M Saiful Bari"],"categories":null,"content":"","date":1537459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537459200,"objectID":"4903b68db721accb86404608fd07e3b8","permalink":"https://sbmaruf.github.io/publication/data-analytics-book/","publishdate":"2018-09-21T00:00:00+08:00","relpermalink":"/publication/data-analytics-book/","section":"publication","summary":"This book chapter goes through various aspects of regression and maths behind them.","tags":["regression","data-analytics","book"],"title":"Data Analytics: Concepts, Techniques and Applications","type":"publication"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536422400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536422400,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"https://sbmaruf.github.io/tutorial/example/","publishdate":"2018-09-09T00:00:00+08:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":[],"categories":null,"content":"Special thanks to the author Emma Strubell for replying some of the query by mail.\n Click on the **Slides** button above to view the built-in slides feature.   -- ","date":1524655800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524655800,"objectID":"fc1a304f7347839c0880710f727ffb81","permalink":"https://sbmaruf.github.io/talk/idcnn/","publishdate":"2018-04-25T00:00:00+08:00","relpermalink":"/talk/idcnn/","section":"talk","summary":"This talk summarizes the paper [`Fast and Accurate Entity Recognition with Iterated Dilated Convolutions`](https://arxiv.org/abs/1702.02098).","tags":["Deep-Learning"],"title":"Iterated Dilated Convolutions for NLP - NER as an example","type":"talk"},{"authors":[],"categories":null,"content":" Click on the **Slides** button above to view the built-in slides feature.   -- ","date":1521631800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1521631800,"objectID":"2f728de662943cb2c7f01ad9606f77a0","permalink":"https://sbmaruf.github.io/talk/attention/","publishdate":"2018-03-21T00:00:00+08:00","relpermalink":"/talk/attention/","section":"talk","summary":"This talk summarizes the paper [`Effective Approaches to Attention-based Neural Machine Translation`](https://arxiv.org/abs/1508.04025).","tags":["Deep-Learning"],"title":"Attention Mechanism","type":"talk"},{"authors":[],"categories":null,"content":" Click on the **Slides** button above to view the built-in slides feature.   -- ","date":1521023400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1521023400,"objectID":"1eab63e31962551d6962e6ba8f7f9b58","permalink":"https://sbmaruf.github.io/talk/encode-decode-architecture/","publishdate":"2018-03-14T00:00:00+08:00","relpermalink":"/talk/encode-decode-architecture/","section":"talk","summary":"This talk summarizes the paper [`Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation`](https://arxiv.org/abs/1406.1078).","tags":["Deep-Learning"],"title":"Encode Decode Architecture","type":"talk"},{"authors":[],"categories":null,"content":" Click on the **Slides** button above to view the built-in slides feature.   -- ","date":1520431200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1520431200,"objectID":"098067c2d70f6fdfaf7b7e6af86ee4b1","permalink":"https://sbmaruf.github.io/talk/structure-of-rnn-cells/","publishdate":"2018-03-07T00:00:00+08:00","relpermalink":"/talk/structure-of-rnn-cells/","section":"talk","summary":"A talk on the structures of RNN cells.","tags":["deep-learning","architecture"],"title":"Structure of RNN Cells","type":"talk"},{"authors":["M Saiful Bari"],"categories":null,"content":" Academic makes it easy to create a beautiful website for free using Markdown. Customize anything on your site with widgets, themes, and language packs.\nFollow our easy step by step guide to learn how to build your own free website with Academic. Check out the personal demo or the business demo of what you\u0026rsquo;ll get in less than 10 minutes.\n View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an Academic sticker Wear the T-shirt   \nKey features:\n Easily manage various content including homepage, blog posts, publications, talks, and projects Extensible via color themes and widgets/plugins Write in Markdown for easy formatting and code highlighting, with LaTeX for mathematical expressions Social/academic network linking, Google Analytics, and Disqus comments Responsive and mobile friendly Simple and refreshing one page design Multilingual and easy to customize  Color Themes Academic is available in different color themes and font themes.\n         Ecosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Quick install using your web browser  Install Academic with Netlify  Netlify will provide you with a customizable URL to access your new site  On GitHub, go to your newly created academic-kickstart repository and edit config.toml to personalize your site. Shortly after saving the file, your site will automatically update Read the Quick Start Guide to learn how to add Markdown content. For inspiration, refer to the Markdown content which powers the Demo  Install with Git Prerequisites:\n Download and install Git Download and install Hugo   Fork the Academic Kickstart repository and clone your fork with Git:\ngit clone https://github.com/sourcethemes/academic-kickstart.git My_Website  Note that if you forked Academic Kickstart, the above command should be edited to clone your fork, i.e. replace sourcethemes with your GitHub username.\n Initialize the theme:\ncd My_Website git submodule update --init --recursive   Install with ZIP  Download and extract Academic Kickstart Download and extract the Academic theme to the themes/academic/ folder from the above step  Install with RStudio View the guide to installing Academic with RStudio\nQuick start  If you installed on your computer, view your new website by running the following command:\nhugo server  Now visit localhost:1313 and your new Academic powered website will appear. Otherwise, if using Netlify, they will provide you with your URL.\n Read the Quick Start Guide to learn how to add Markdown content, customize your site, and deploy it. For inspiration, refer to the Markdown content which powers the Demo\n Build your site by running the hugo command. Then host it for free using Github Pages or Netlify (refer to the first installation method). Alternatively, copy the generated public/ directory (by FTP, Rsync, etc.) to your production web server (such as a university\u0026rsquo;s hosting service).\n  Updating Feel free to star the project on Github to help keep track of updates and check out the release notes prior to updating your site.\nBefore updating the framework, it is recommended to make a backup of your entire website directory (or at least your themes/academic directory) and record your current version number.\nBy default, Academic is installed as a Git submodule which can be updated by running the following command:\ngit submodule update --remote --merge  Check out the update guide for full instructions and alternative methods.\nFeedback \u0026amp; Contributing Please use the issue tracker to let me know about any bugs or feature requests, or alternatively make a pull request.\nFor support, head over to the Hugo discussion forum.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515772800,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://sbmaruf.github.io/post/getting-started/","publishdate":"2016-04-20T00:00:00+08:00","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website or blog in under 10 minutes.","tags":["Academic"],"title":"Academic: the website designer for Hugo","type":"post"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"https://sbmaruf.github.io/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]